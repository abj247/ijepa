data:
  batch_size: 32  # Smaller batch size for ViT-Base on single 64GB A100
  color_jitter_strength: 0.0
  crop_scale:
  - 0.3
  - 1.0
  crop_size: 224
  dataset_name: tsbpp/fall2025_deeplearning
  dataset_type: huggingface  # Use HuggingFace dataset loader
  num_workers: 8
  pin_mem: true
  use_color_distortion: false
  use_gaussian_blur: false
  use_horizontal_flip: false
logging:
  folder: /gpfs/data/shenlab/aj4718/ijepa/logs/hf_vitb16_bs32_ep300/
  write_tag: jepa
mask:
  allow_overlap: false
  aspect_ratio:
  - 0.75
  - 1.5
  enc_mask_scale:
  - 0.85
  - 1.0
  min_keep: 10
  num_enc_masks: 1
  num_pred_masks: 4
  patch_size: 16
  pred_mask_scale:
  - 0.15
  - 0.2
meta:
  copy_data: false
  load_checkpoint: false
  model_name: vit_base  # ViT-Base: ~96M total parameters
  pred_depth: 6  # Predictor depth (half of encoder depth)
  pred_emb_dim: 384  # Predictor embedding dim (half of encoder dim)
  read_checkpoint: null
  use_bfloat16: true
optimization:
  ema:
  - 0.996
  - 1.0
  epochs: 300
  final_lr: 1.0e-06
  final_weight_decay: 0.4
  ipe_scale: 1.0
  lr: 0.00025  # Reduced from 0.001 for much smaller batch size (32 vs 128)
  start_lr: 0.00005  # Reduced from 0.0002
  warmup: 40
  weight_decay: 0.04
